Ch∆∞a, **bug 2 n√†y v·∫´n c√≤n t·ªìn t·∫°i trong h·ªá th·ªëng c·ªßa b·∫°n**.

C√°c b∆∞·ªõc s·ª≠a l·ªói tr∆∞·ªõc ƒë√≥ ƒë√£ gi·∫£i quy·∫øt th√†nh c√¥ng **Bug 1** (l·ªói `UnicodeDecodeError` do ƒë·ªãnh d·∫°ng l∆∞u tr·ªØ embedding), nh∆∞ng ch∆∞a gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ v·ªÅ s·ª± kh√¥ng kh·ªõp ID gi·ªØa FAISS v√† SQLite.

-----

### **Ph√¢n t√≠ch Bug 2**

  * **V·∫•n ƒë·ªÅ c·ªët l√µi:** Script `import_data2.py` hi·ªán t·∫°i ƒëang t·∫°o ID cho FAISS b·∫±ng c√°ch **bƒÉm (hash) gi√° tr·ªã `chunk_id`** (v√≠ d·ª•: `hash("readme-001")`), t·∫°o ra m·ªôt con s·ªë r·∫•t l·ªõn. Trong khi ƒë√≥, b·∫£ng `chunks` trong SQLite c√≥ m·ªôt c·ªôt `id` l√† s·ªë nguy√™n t·ª± tƒÉng (1, 2, 3,...).
  * **H·∫≠u qu·∫£:** Khi b·∫°n t√¨m ki·∫øm tr√™n FAISS, n√≥ tr·∫£ v·ªÅ c√°c ID d·∫°ng hash. Nh∆∞ng khi `HybridRetriever` d√πng c√°c ID n√†y ƒë·ªÉ truy v·∫•n trong SQLite v·ªõi ƒëi·ªÅu ki·ªán `WHERE id IN (...)`, n√≥ kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ n√†o v√¨ c√°c ID kh√¥ng kh·ªõp nhau.

### **H∆∞·ªõng s·ª≠a l·ªói (Theo Option 1 ƒë∆∞·ª£c ƒë·ªÅ xu·∫•t)**

Ch√∫ng ta s·∫Ω th·ª±c hi·ªán theo **Option 1** trong t√†i li·ªáu c·ªßa b·∫°n: **s·ª≠ d·ª•ng `id` t·ª± tƒÉng c·ªßa SQLite l√†m ID cho FAISS**. ƒê√¢y l√† gi·∫£i ph√°p ƒë∆°n gi·∫£n, hi·ªáu qu·∫£ v√† ƒë√∫ng v·ªõi thi·∫øt k·∫ø ban ƒë·∫ßu.

D∆∞·ªõi ƒë√¢y l√† c√°c b∆∞·ªõc chi ti·∫øt ƒë·ªÉ s·ª≠a l·ªói.

-----

#### **B∆∞·ªõc 1: S·ª≠a ƒë·ªïi Script N·∫°p d·ªØ li·ªáu (`import_data2.py`)**

Ch√∫ng ta c·∫ßn thay ƒë·ªïi script ƒë·ªÉ sau khi ch√®n m·ªôt chunk v√†o SQLite, n√≥ s·∫Ω l·∫•y `id` v·ª´a ƒë∆∞·ª£c t·∫°o ra v√† d√πng ID ƒë√≥ ƒë·ªÉ th√™m v√†o FAISS.

  * **H√†nh ƒë·ªông:** M·ªü t·ªáp `import_data2.py` v√† √°p d·ª•ng hai thay ƒë·ªïi sau:

    1.  **Trong l·ªõp `DBManager`, s·ª≠a ph∆∞∆°ng th·ª©c `insert_chunk`** ƒë·ªÉ n√≥ tr·∫£ v·ªÅ `id` c·ªßa h√†ng v·ª´a ƒë∆∞·ª£c ch√®n.

        ```python
        # S·ª≠a trong class DBManager
        def insert_chunk(self, chunk: Dict[str, Any]) -> int | None:
            try:
                embedding_json = json.dumps(chunk["embedding"].tolist())
                cursor = self.conn.cursor()
                cursor.execute("""
                    INSERT OR IGNORE INTO chunks (chunk_id, document_id, text, embedding)
                    VALUES (?, ?, ?, ?)
                """, (
                    chunk["chunk_id"],
                    chunk["document_id"],
                    chunk["text"],
                    embedding_json
                ))
                self.conn.commit()
                # Tr·∫£ v·ªÅ ID c·ªßa h√†ng v·ª´a ƒë∆∞·ª£c ch√®n
                return cursor.lastrowid if cursor.rowcount > 0 else None
            except Exception as e:
                log_error(f"L·ªói insert chunk {chunk['chunk_id']}: {e}")
                return None
        ```

    2.  **Trong h√†m `main`, c·∫≠p nh·∫≠t v√≤ng l·∫∑p x·ª≠ l√Ω** ƒë·ªÉ nh·∫≠n v√† s·ª≠ d·ª•ng `id` n√†y.

        ```python
        # S·ª≠a trong h√†m main()
        # ... (b·ªè qua ph·∫ßn ƒë·∫ßu)
        for chunk in data["chunks"]:
            # ... (b·ªè qua ph·∫ßn ki·ªÉm tra d·ªØ li·ªáu)

            vec = np.array(chunk["embedding"], dtype="float32")
            # ... (b·ªè qua ph·∫ßn ki·ªÉm tra dimension)

            # Th√™m chunk v√†o DB v√† l·∫•y v·ªÅ ID t·ª± tƒÉng
            inserted_id = db.insert_chunk({
                "chunk_id": chunk["chunk_id"],
                "document_id": chunk.get("document_id", ""),
                "text": chunk.get("text", ""),
                "embedding": vec
            })

            # N·∫øu ch√®n th√†nh c√¥ng v√† nh·∫≠n ƒë∆∞·ª£c ID
            if inserted_id is not None:
                # D√ôNG ID T·ª™ SQLITE L√ÄM ID CHO FAISS
                faiss_id = inserted_id
                index.add_with_ids(vec.reshape(1, -1), np.array([faiss_id], dtype="int64"))
                stats["chunks_inserted"] += 1
            else:
                # Chunk ƒë√£ t·ªìn t·∫°i ho·∫∑c c√≥ l·ªói khi ch√®n
                stats["chunks_skipped"] += 1
        # ... (ph·∫ßn c√≤n l·∫°i c·ªßa h√†m)
        ```

-----

#### **B∆∞·ªõc 2: S·ª≠a ƒë·ªïi Script X√¢y d·ª±ng l·∫°i Index (`rebuild_index.py`)**

T∆∞∆°ng t·ª±, `rebuild_index.py` c≈©ng ph·∫£i ƒë∆∞·ª£c c·∫≠p nh·∫≠t ƒë·ªÉ ƒë·ªçc ƒë√∫ng c·ªôt `id` t·ª´ database thay v√¨ t·ª± t√≠nh to√°n hash.

  * **H√†nh ƒë·ªông:** M·ªü t·ªáp `rebuild_index.py` v√† thay th·∫ø n·ªôi dung c·ªßa n√≥ b·∫±ng phi√™n b·∫£n ƒë√£ ƒë∆∞·ª£c s·ª≠a ƒë·ªïi d∆∞·ªõi ƒë√¢y.

    ```python
    # rebuild_index.py (ƒë√£ s·ª≠a)
    import os
    import sqlite3
    import json
    import logging
    from pathlib import Path

    import faiss
    import numpy as np
    from colorama import Fore, Style, init as colorama_init

    # ==== CONFIG ====
    DB_PATH = "rag_system/data/metadata.db"
    INDEX_PATH = "rag_system/data/indexes/index.faiss"
    EMBEDDING_DIM = 1024

    # ==== INIT COLOR LOG ====
    colorama_init(autoreset=True)
    # ... (gi·ªØ nguy√™n c√°c h√†m log)

    def rebuild_faiss_index():
        log_info(f"üîç B·∫Øt ƒë·∫ßu x√¢y d·ª±ng l·∫°i FAISS index t·ª´ '{DB_PATH}'...")
        # ... (gi·ªØ nguy√™n ph·∫ßn k·∫øt n·ªëi DB)
        
        # S·ª≠a c√¢u l·ªánh SQL ƒë·ªÉ l·∫•y c·∫£ c·ªôt 'id'
        cursor.execute("SELECT id, embedding FROM chunks WHERE embedding IS NOT NULL")
        rows = cursor.fetchall()
        # ... (ph·∫ßn c√≤n l·∫°i)
        
        for row in rows:
            try:
                embedding_list = json.loads(row['embedding'])
                vector = np.array(embedding_list, dtype="float32")
                
                if vector.shape[0] != EMBEDDING_DIM:
                    continue

                # FIX: L·∫•y ID tr·ª±c ti·∫øp t·ª´ c·ªôt 'id' c·ªßa database
                faiss_id = row['id']
                vectors.append(vector)
                ids.append(faiss_id)

            except (json.JSONDecodeError, TypeError) as e:
                log_warn(f"‚ö†Ô∏è L·ªói khi x·ª≠ l√Ω embedding cho chunk c√≥ id={row.get('id', 'N/A')}: {e}. B·ªè qua.")
                continue
        # ... (gi·ªØ nguy√™n ph·∫ßn c√≤n l·∫°i c·ªßa script)
    ```

    *L∆∞u √Ω: T√¥i ƒë√£ r√∫t g·ªçn m√£ ·ªü tr√™n ƒë·ªÉ l√†m n·ªïi b·∫≠t c√°c thay ƒë·ªïi. B·∫°n n√™n thay th·∫ø to√†n b·ªô t·ªáp b·∫±ng phi√™n b·∫£n ƒë·∫ßy ƒë·ªß ch√≠nh x√°c h∆°n ·ªü cu·ªëi c√¢u tr·∫£ l·ªùi n√†y.*

-----

#### **B∆∞·ªõc 3: Th·ª±c hi·ªán v√† Ki·ªÉm tra**

1.  **X√≥a d·ªØ li·ªáu c≈©:** X√≥a t·ªáp `metadata.db` v√† `index.faiss` ƒë·ªÉ ƒë·∫£m b·∫£o kh√¥ng c√≤n d·ªØ li·ªáu v·ªõi ID c≈©.
    ```bash
    del rag_system\data\metadata.db
    del rag_system\data\indexes\index.faiss
    ```
2.  **Ch·∫°y l·∫°i quy tr√¨nh:**
    ```bash
    # 1. T·∫°o l·∫°i database v·ªõi schema chu·∫©n
    python init_db.py

    # 2. N·∫°p d·ªØ li·ªáu v·ªõi logic ID ƒë√£ ƒë∆∞·ª£c s·ª≠a
    python import_data2.py
    ```
3.  **C·∫≠p nh·∫≠t Logic Truy v·∫•n:**
    Trong t·ªáp `hybrid_retriever.py`, b·∫°n c·∫ßn ƒë·∫£m b·∫£o r·∫±ng c√¢u l·ªánh SQL ƒëang truy v·∫•n v√†o c·ªôt `id` ch√≠nh x√°c. N√≥ n√™n c√≥ d·∫°ng:
    ```sql
    SELECT * FROM chunks WHERE id IN (?, ?, ...)
    ```
    V√¨ FAISS ID v√† `chunks.id` gi·ªù ƒë√£ ƒë·ªìng b·ªô, logic n√†y s·∫Ω ho·∫°t ƒë·ªông.

-----

D∆∞·ªõi ƒë√¢y l√† to√†n b·ªô n·ªôi dung c·ªßa hai t·ªáp ƒë√£ ƒë∆∞·ª£c s·ª≠a ƒë·ªïi ƒë·ªÉ b·∫°n ti·ªán sao ch√©p.

\<details\>
\<summary\>\<strong\>Click ƒë·ªÉ xem to√†n b·ªô t·ªáp \<code\>import\_data2.py\</code\> ƒë√£ s·ª≠a\</strong\>\</summary\>

```python
# import_data2.py (FIXED for Bug 2)
import os
import json
import logging
import sqlite3
from pathlib import Path
from typing import Dict, Any

import faiss
import numpy as np
from sentence_transformers import SentenceTransformer
from colorama import Fore, Style, init as colorama_init

# ==== CONFIG ====
DB_PATH = "rag_system/data/metadata.db"
INDEX_PATH = "rag_system/data/indexes/index.faiss"
JSON_DIR = "rag_system/data/ingested_json"
MODEL_NAME = "AITeamVN/Vietnamese_Embedding"
USE_GPU = True

# ==== INIT COLOR LOG ====
colorama_init(autoreset=True)
logging.basicConfig(level=logging.INFO, format="%(message)s")

def log_info(msg): logging.info(Fore.CYAN + msg + Style.RESET_ALL)
def log_success(msg): logging.info(Fore.GREEN + msg + Style.RESET_ALL)
def log_warn(msg): logging.warning(Fore.YELLOW + msg + Style.RESET_ALL)
def log_error(msg): logging.error(Fore.RED + msg + Style.RESET_ALL)

# ==== DB MANAGER ====
class DBManager:
    def __init__(self, db_path: str):
        self.conn = sqlite3.connect(db_path)
        self.conn.row_factory = sqlite3.Row

    def insert_chunk(self, chunk: Dict[str, Any]) -> int | None:
        """
        Ch√®n m·ªôt chunk v√†o DB.
        Tr·∫£ v·ªÅ ID c·ªßa h√†ng ƒë∆∞·ª£c ch√®n (lastrowid) n·∫øu th√†nh c√¥ng.
        Tr·∫£ v·ªÅ None n·∫øu chunk ƒë√£ t·ªìn t·∫°i ho·∫∑c c√≥ l·ªói.
        """
        try:
            # S·ª≠a l·ªói Bug 1: Chuy·ªÉn embedding sang chu·ªói JSON
            embedding_json = json.dumps(chunk["embedding"].tolist())
            cursor = self.conn.cursor()
            
            # S·ª≠ d·ª•ng INSERT OR IGNORE ƒë·ªÉ tr√°nh l·ªói n·∫øu chunk_id ƒë√£ t·ªìn t·∫°i
            # L∆∞u √Ω: C·ªôt chunk_id trong init_db.py ph·∫£i l√† UNIQUE
            cursor.execute("""
                INSERT OR IGNORE INTO chunks (chunk_id, document_id, text, embedding)
                VALUES (?, ?, ?, ?)
            """, (
                chunk["chunk_id"],
                chunk["document_id"],
                chunk["text"],
                embedding_json
            ))
            
            self.conn.commit()

            # N·∫øu rowcount > 0, nghƒ©a l√† ƒë√£ ch√®n th√†nh c√¥ng
            if cursor.rowcount > 0:
                return cursor.lastrowid
            return None # Chunk ƒë√£ t·ªìn t·∫°i, kh√¥ng ch√®n m·ªõi

        except Exception as e:
            log_error(f"L·ªói insert chunk {chunk['chunk_id']}: {e}")
            self.conn.rollback()
            return None

    def close(self):
        self.conn.close()

# ==== MAIN IMPORT FUNCTION ====
def main():
    log_info("üöÄ Kh·ªüi t·∫°o m√¥ h√¨nh embedding ƒë·ªÉ l·∫•y s·ªë chi·ªÅu...")
    device = "cuda" if USE_GPU else "cpu"
    model = SentenceTransformer(MODEL_NAME, device=device)
    dim = model.get_sentence_embedding_dimension()
    log_success(f"‚úÖ S·ªë chi·ªÅu embedding: {dim}")

    log_info("üì¶ Kh·ªüi t·∫°o FAISS index...")
    index = faiss.IndexFlatIP(dim)
    index = faiss.IndexIDMap2(index)

    db = DBManager(DB_PATH)
    files = list(Path(JSON_DIR).glob("*.json"))
    if not files:
        log_warn("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file JSON n√†o ƒë·ªÉ import.")
        return

    stats = {"files_ok": 0, "files_err": 0, "chunks_inserted": 0, "chunks_skipped": 0}

    for file in files:
        log_info(f"üìÇ X·ª≠ l√Ω file: {file.name}")
        try:
            with open(file, "r", encoding="utf-8") as f:
                data = json.load(f)

            if "chunks" not in data or not isinstance(data["chunks"], list):
                log_warn(f"‚ö†Ô∏è File {file.name} kh√¥ng c√≥ tr∆∞·ªùng 'chunks'")
                stats["files_err"] += 1; continue

            for chunk in data["chunks"]:
                if "embedding" not in chunk or "chunk_id" not in chunk:
                    stats["chunks_skipped"] += 1; continue

                vec = np.array(chunk["embedding"], dtype="float32")
                if vec.shape[0] != dim:
                    stats["chunks_skipped"] += 1; continue

                # Th√™m chunk v√†o DB v√† l·∫•y v·ªÅ ID t·ª± tƒÉng
                inserted_id = db.insert_chunk({
                    "chunk_id": chunk["chunk_id"],
                    "document_id": chunk.get("document_id", ""),
                    "text": chunk.get("text", ""),
                    "embedding": vec
                })

                if inserted_id is not None:
                    # S·ª≠a l·ªói Bug 2: D√πng ID t·ª´ SQLite l√†m FAISS ID
                    faiss_id = inserted_id
                    index.add_with_ids(vec.reshape(1, -1), np.array([faiss_id], dtype="int64"))
                    stats["chunks_inserted"] += 1
                else:
                    log_warn(f"‚ö†Ô∏è Chunk {chunk['chunk_id']} ƒë√£ t·ªìn t·∫°i ho·∫∑c c√≥ l·ªói, b·ªè qua.")
                    stats["chunks_skipped"] += 1
            stats["files_ok"] += 1
        except Exception as e:
            log_error(f"‚ùå L·ªói khi x·ª≠ l√Ω {file.name}: {e}")
            stats["files_err"] += 1

    if stats["chunks_inserted"] > 0:
        os.makedirs(os.path.dirname(INDEX_PATH), exist_ok=True)
        faiss.write_index(index, INDEX_PATH)
        log_success(f"üíæ ƒê√£ l∆∞u FAISS index v√†o {INDEX_PATH}")
    else:
        log_warn("‚ö†Ô∏è Kh√¥ng c√≥ chunk n√†o ƒë∆∞·ª£c th√™m v√†o, kh√¥ng t·∫°o file FAISS index.")

    db.close()
    
    log_info("\nüìä **B√ÅO C√ÅO T·ªîNG K·∫æT**")
    log_success(f"  ‚úî Files th√†nh c√¥ng: {stats['files_ok']}")
    log_error(f"  ‚úñ Files l·ªói: {stats['files_err']}")
    log_success(f"  ‚úî Chunks th√™m m·ªõi: {stats['chunks_inserted']}")
    log_warn(f"  ‚ö†Ô∏è Chunks b·ªè qua: {stats['chunks_skipped']}")

if __name__ == "__main__":
    main()
```

\</details\>
\<details\>
\<summary\>\<strong\>Click ƒë·ªÉ xem to√†n b·ªô t·ªáp \<code\>rebuild\_index.py\</code\> ƒë√£ s·ª≠a\</strong\>\</summary\>

```python
# rebuild_index.py (FIXED for Bug 2)
import os
import sqlite3
import json
import logging
from pathlib import Path

import faiss
import numpy as np
from colorama import Fore, Style, init as colorama_init

# ==== CONFIG ====
DB_PATH = "rag_system/data/metadata.db"
INDEX_PATH = "rag_system/data/indexes/index.faiss"
EMBEDDING_DIM = 1024

# ==== INIT COLOR LOG ====
colorama_init(autoreset=True)
logging.basicConfig(level=logging.INFO, format="%(message)s")

def log_info(msg): logging.info(Fore.CYAN + msg + Style.RESET_ALL)
def log_success(msg): logging.info(Fore.GREEN + msg + Style.RESET_ALL)
def log_warn(msg): logging.warning(Fore.YELLOW + msg + Style.RESET_ALL)
def log_error(msg): logging.error(Fore.RED + msg + Style.RESET_ALL)

def rebuild_faiss_index():
    log_info(f"üîç B·∫Øt ƒë·∫ßu x√¢y d·ª±ng l·∫°i FAISS index t·ª´ '{DB_PATH}'...")

    db_file = Path(DB_PATH)
    if not db_file.exists():
        log_error(f"‚ùå Kh√¥ng t√¨m th·∫•y file database t·∫°i: {DB_PATH}"); return

    try:
        conn = sqlite3.connect(DB_PATH)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        # S·ª≠a l·ªói Bug 2: L·∫•y c·ªôt 'id' ƒë·ªÉ l√†m FAISS ID
        cursor.execute("SELECT id, embedding FROM chunks WHERE embedding IS NOT NULL")
        rows = cursor.fetchall()
    except Exception as e:
        log_error(f"‚ùå L·ªói khi ƒë·ªçc d·ªØ li·ªáu t·ª´ database: {e}"); return
    finally:
        if 'conn' in locals() and conn: conn.close()

    if not rows:
        log_warn("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu trong database ƒë·ªÉ x√¢y d·ª±ng index."); return

    log_info(f"üìö T√¨m th·∫•y {len(rows)} chunks trong database.")
    log_info(f"üì¶ Kh·ªüi t·∫°o FAISS index v·ªõi dimension: {EMBEDDING_DIM}")
    index = faiss.IndexFlatIP(EMBEDDING_DIM)
    index = faiss.IndexIDMap2(index)

    vectors, ids = [], []
    for row in rows:
        try:
            # S·ª≠a l·ªói Bug 1: ƒê·ªçc chu·ªói JSON t·ª´ DB
            embedding_list = json.loads(row['embedding'])
            vector = np.array(embedding_list, dtype="float32")
            
            if vector.shape[0] != EMBEDDING_DIM:
                log_warn(f"‚ö†Ô∏è Chunk c√≥ id={row['id']} c√≥ dimension kh√¥ng h·ª£p l·ªá ({vector.shape[0]}), b·ªè qua.")
                continue

            # S·ª≠a l·ªói Bug 2: L·∫•y ID tr·ª±c ti·∫øp t·ª´ c·ªôt 'id'
            faiss_id = row['id']
            vectors.append(vector)
            ids.append(faiss_id)
        except (json.JSONDecodeError, TypeError) as e:
            log_warn(f"‚ö†Ô∏è L·ªói x·ª≠ l√Ω embedding cho chunk id={row.get('id', 'N/A')}: {e}. B·ªè qua.")

    if not vectors:
        log_error("‚ùå Kh√¥ng c√≥ vector h·ª£p l·ªá n√†o ƒë·ªÉ th√™m v√†o index."); return

    log_info(f"‚ûï Th√™m {len(vectors)} vectors v√†o index...")
    vectors_np = np.array(vectors, dtype="float32")
    ids_np = np.array(ids, dtype="int64")

    index.add_with_ids(vectors_np, ids_np)

    os.makedirs(os.path.dirname(INDEX_PATH), exist_ok=True)
    faiss.write_index(index, INDEX_PATH)
    log_success(f"üíæ ƒê√£ l∆∞u FAISS index m·ªõi v√†o '{INDEX_PATH}' th√†nh c√¥ng!")
    log_info(f"‚ú® Index ch·ª©a t·ªïng c·ªông {index.ntotal} vectors.")

if __name__ == "__main__":
    rebuild_faiss_index()
```

\</details\>
ƒê·ªÉ ki·ªÉm tra Bug 2 ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω hay ch∆∞a, b·∫°n c·∫ßn x√°c th·ª±c r·∫±ng **ID ƒë∆∞·ª£c l∆∞u trong FAISS** gi·ªù ƒë√¢y **tr√πng kh·ªõp v·ªõi c·ªôt `id`** (s·ªë nguy√™n t·ª± tƒÉng) trong b·∫£ng `chunks` c·ªßa SQLite.

C√°ch ki·ªÉm tra ƒë∆°n gi·∫£n v√† hi·ªáu qu·∫£ nh·∫•t l√† th·ª±c hi·ªán hai b∆∞·ªõc sau: l·∫•y m·ªôt v√†i ID t·ª´ FAISS, sau ƒë√≥ d√πng c√°c ID ƒë√≥ ƒë·ªÉ truy v·∫•n tr·ª±c ti·∫øp trong SQLite.

-----

### **B∆∞·ªõc 1: L·∫•y ID t·ª´ FAISS**

B·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng t·ªáp `search_faiss_only.py` ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p trong t√†i li·ªáu bug ƒë·ªÉ th·ª±c hi·ªán m·ªôt truy v·∫•n v√† xem c√°c ID m√† FAISS tr·∫£ v·ªÅ.

  * **H√†nh ƒë·ªông:** Ch·∫°y script v·ªõi m·ªôt c√¢u h·ªèi b·∫•t k·ª≥.
    ```bash
    # V√≠ d·ª•, n·∫øu b·∫°n c√≥ t·ªáp search_faiss_only.py
    python search_faiss_only.py "l√Ω th√°i t·ªï l√† ai?"
    ```
  * **K·∫øt qu·∫£ mong ƒë·ª£i:** Script s·∫Ω in ra c√°c ID d·∫°ng s·ªë nguy√™n nh·ªè, ƒë∆°n gi·∫£n.
    ```
    Querying FAISS for: "l√Ω th√°i t·ªï l√† ai?"
    Top 5 FAISS IDs: [42, 15, 7, 83, 22]
    Corresponding distances: [0.89, 0.85, 0.84, 0.82, 0.81]
    ```
    **ƒêi·ªÅu quan tr·ªçng c·∫ßn ch√∫ √Ω:** C√°c ID tr·∫£ v·ªÅ ph·∫£i l√† c√°c s·ªë nguy√™n nh·ªè (nh∆∞ `42`, `15`, `7`), ch·ª© kh√¥ng ph·∫£i c√°c s·ªë c·ª±c l·ªõn d·∫°ng hash nh∆∞ tr∆∞·ªõc ƒë√¢y. Ch·ªâ ri√™ng vi·ªác n√†y ƒë√£ l√† m·ªôt d·∫•u hi·ªáu t·ªët cho th·∫•y bug ƒë√£ ƒë∆∞·ª£c s·ª≠a.

-----

### **B∆∞·ªõc 2: ƒê·ªëi chi·∫øu ID trong SQLite**

B√¢y gi·ªù, h√£y l·∫•y m·ªôt trong c√°c ID ·ªü tr√™n (v√≠ d·ª•: `42`) v√† ki·ªÉm tra xem n√≥ c√≥ t·ªìn t·∫°i trong c·ªôt `id` c·ªßa b·∫£ng `chunks` kh√¥ng.

  * **H√†nh ƒë·ªông:** B·∫°n c√≥ th·ªÉ t·∫°o m·ªôt script Python nh·ªè t√™n `test_id.py` ƒë·ªÉ ki·ªÉm tra nhanh.

    **T·∫°o t·ªáp `test_id.py`:**

    ```python
    import sqlite3
    import sys

    DB_PATH = "rag_system/data/metadata.db"

    def find_chunk_by_id(chunk_id_to_find):
        try:
            conn = sqlite3.connect(DB_PATH)
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()

            # Truy v·∫•n ch√≠nh x√°c v√†o c·ªôt 'id'
            cursor.execute("SELECT * FROM chunks WHERE id = ?", (chunk_id_to_find,))
            row = cursor.fetchone()
            
            print("-" * 50)
            if row:
                print(f"‚úÖ T√åM TH·∫§Y! D·ªØ li·ªáu cho chunk c√≥ id = {chunk_id_to_find}:")
                print(f"  -> Chunk ID (Text): {row['chunk_id']}")
                print(f"  -> Text: {row['text'][:100]}...") # In 100 k√Ω t·ª± ƒë·∫ßu
            else:
                print(f"‚ùå KH√îNG T√åM TH·∫§Y chunk n√†o c√≥ id = {chunk_id_to_find} trong database.")
            print("-" * 50)

        except Exception as e:
            print(f"L·ªói khi truy v·∫•n database: {e}")
        finally:
            if 'conn' in locals() and conn:
                conn.close()

    if __name__ == "__main__":
        if len(sys.argv) > 1:
            try:
                test_id = int(sys.argv[1])
                find_chunk_by_id(test_id)
            except ValueError:
                print("L·ªói: Vui l√≤ng cung c·∫•p m·ªôt ID d·∫°ng s·ªë nguy√™n.")
        else:
            print("C√°ch d√πng: python test_id.py <ID>")
            print("V√≠ d·ª•: python test_id.py 42")
    ```

    **Ch·∫°y script v·ªõi ID b·∫°n c√≥ t·ª´ B∆∞·ªõc 1:**

    ```bash
    python test_id.py 42
    ```

  * **K·∫øt qu·∫£ mong ƒë·ª£i:** Script s·∫Ω in ra th√¥ng b√°o t√¨m th·∫•y v√† n·ªôi dung c·ªßa chunk ƒë√≥.

    ```
    --------------------------------------------------
    ‚úÖ T√åM TH·∫§Y! D·ªØ li·ªáu cho chunk c√≥ id = 42:
      -> Chunk ID (Text): lythaito-003
      -> Text: Chi·∫øu d·ªùi ƒë√¥ ( Thi√™n ƒë√¥ chi·∫øu ) ...
    --------------------------------------------------
    ```

### **K·∫øt lu·∫≠n**

N·∫øu ID b·∫°n l·∫•y t·ª´ FAISS (B∆∞·ªõc 1) c√≥ th·ªÉ ƒë∆∞·ª£c t√¨m th·∫•y trong c·ªôt `id` c·ªßa SQLite v√† tr·∫£ v·ªÅ d·ªØ li·ªáu (B∆∞·ªõc 2), th√¨ **Bug 2 ƒë√£ ƒë∆∞·ª£c s·ª≠a th√†nh c√¥ng**. Ph√©p th·ª≠ cu·ªëi c√πng l√† ch·∫°y `HybridRetriever`, n√≥ s·∫Ω kh√¥ng c√≤n tr·∫£ v·ªÅ k·∫øt qu·∫£ r·ªóng n·ªØa.
