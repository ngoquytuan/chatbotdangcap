# import_data.py (FINAL, compatible with database.py)
import os
import json
import logging
from pathlib import Path
from typing import Dict, Any

import faiss
import numpy as np
from sentence_transformers import SentenceTransformer
from colorama import Fore, Style, init as colorama_init

# Import lá»›p quáº£n lÃ½ DB tá»« chÃ­nh há»‡ thá»‘ng cá»§a báº¡n
from rag_system.api_service.utils.database import DatabaseManager

# ==== CONFIG ====
INDEX_PATH = "rag_system/data/indexes/index.faiss"
JSON_DIR = "rag_system/data/ingested_json"
MODEL_NAME = "AITeamVN/Vietnamese_Embedding"
USE_GPU = True

# ==== INIT COLOR LOG ====
colorama_init(autoreset=True)
logging.basicConfig(level=logging.INFO, format="%(message)s")
def log_info(msg): logging.info(Fore.CYAN + msg + Style.RESET_ALL)
def log_success(msg): logging.info(Fore.GREEN + msg + Style.RESET_ALL)
def log_warn(msg): logging.warning(Fore.YELLOW + msg + Style.RESET_ALL)
def log_error(msg): logging.error(Fore.RED + msg + Style.RESET_ALL)

def upsert_document(db: DatabaseManager, doc_data: Dict[str, Any]) -> None:
    """ChÃ¨n hoáº·c cáº­p nháº­t thÃ´ng tin tÃ i liá»‡u."""
    doc_id = doc_data['document_id']
    with db.get_cursor() as cursor:
        cursor.execute("SELECT id FROM documents WHERE document_id = ?", (doc_id,))
        exists = cursor.fetchone()

        # Dá»¯ liá»‡u cáº§n chÃ¨n hoáº·c cáº­p nháº­t
        doc_payload = {
            'document_id': doc_id,
            'title': doc_data['title'],
            'source': doc_data.get('source', 'Unknown'),
            'version': doc_data.get('version', '1.0'),
            'language': doc_data.get('language', 'vi'),
            'processing_status': 'processing' # Báº¯t Ä‘áº§u xá»­ lÃ½
        }

        if exists:
            # Cáº­p nháº­t tráº¡ng thÃ¡i náº¿u tÃ i liá»‡u Ä‘Ã£ tá»“n táº¡i
            cursor.execute("""
                UPDATE documents 
                SET title = :title, source = :source, version = :version, 
                    language = :language, processing_status = :processing_status
                WHERE document_id = :document_id
            """, doc_payload)
        else:
            # ChÃ¨n má»›i
            cursor.execute("""
                INSERT INTO documents (document_id, title, source, version, language, processing_status)
                VALUES (:document_id, :title, :source, :version, :language, :processing_status)
            """, doc_payload)

def update_document_status(db: DatabaseManager, doc_id: str, status: str, num_chunks: int):
    """Cáº­p nháº­t tráº¡ng thÃ¡i sau khi xá»­ lÃ½ xong."""
    with db.get_cursor() as cursor:
        cursor.execute("""
            UPDATE documents SET processing_status = ?, total_chunks = ? WHERE document_id = ?
        """, (status, num_chunks, doc_id))

def main():
    log_info("ğŸš€ Khá»Ÿi táº¡o mÃ´ hÃ¬nh embedding...")
    model = SentenceTransformer(MODEL_NAME, device="cuda" if USE_GPU else "cpu")
    dim = model.get_sentence_embedding_dimension()
    log_success(f"âœ… Sá»‘ chiá»u embedding: {dim}")

    log_info("ğŸ“¦ Khá»Ÿi táº¡o FAISS index...")
    index = faiss.IndexFlatIP(dim)
    index = faiss.IndexIDMap2(index)

    # Sá»­ dá»¥ng DatabaseManager tá»« há»‡ thá»‘ng
    db = DatabaseManager()
    files = list(Path(JSON_DIR).glob("*.json"))
    if not files:
        log_warn("âš ï¸ KhÃ´ng tÃ¬m tháº¥y file JSON nÃ o."); return

    stats = {"docs": 0, "chunks_inserted": 0, "chunks_skipped": 0}

    for file in files:
        log_info(f"ğŸ“‚ Xá»­ lÃ½ file: {file.name}")
        try:
            with open(file, "r", encoding="utf-8") as f: data = json.load(f)
            doc_id = data.get('document_id')
            if not doc_id:
                log_warn(f"âš ï¸ File {file.name} thiáº¿u 'document_id', bá» qua."); continue

            # BÆ°á»›c 1: ChÃ¨n/Cáº­p nháº­t tÃ i liá»‡u vÃ  Ä‘áº·t tráº¡ng thÃ¡i "processing"
            upsert_document(db, data)
            stats["docs"] += 1

            chunks_in_doc = 0
            for chunk in data.get("chunks", []):
                if "embedding" not in chunk or "chunk_id" not in chunk:
                    stats["chunks_skipped"] += 1; continue

                vec = np.array(chunk["embedding"], dtype="float32")
                if vec.shape[0] != dim:
                    stats["chunks_skipped"] += 1; continue

                # Chuáº©n bá»‹ dá»¯ liá»‡u Ä‘áº§y Ä‘á»§ cho hÃ m insert_chunk cá»§a DatabaseManager
                chunk_payload = {
                    'chunk_id': chunk['chunk_id'],
                    'document_id': doc_id,
                    'title': data.get('title'),
                    'source': data.get('source'),
                    'version': data.get('version', '1.0'),
                    'language': data.get('language', 'vi'),
                    'text': chunk.get('text', ''),
                    'embedding': chunk['embedding'] # Truyá»n list, hÃ m insert_chunk sáº½ xá»­ lÃ½
                }

                inserted_id = db.insert_chunk(chunk_payload)

                if inserted_id:
                    index.add_with_ids(vec.reshape(1, -1), np.array([inserted_id], dtype="int64"))
                    stats["chunks_inserted"] += 1
                    chunks_in_doc += 1
                else:
                    stats["chunks_skipped"] += 1

            # BÆ°á»›c 3: Cáº­p nháº­t tráº¡ng thÃ¡i document thÃ nh "completed"
            update_document_status(db, doc_id, "completed", chunks_in_doc)
            log_success(f"  âœ” HoÃ n táº¥t xá»­ lÃ½ {doc_id} vá»›i {chunks_in_doc} chunks.")

        except Exception as e: 
            log_error(f"âŒ Lá»—i khi xá»­ lÃ½ {file.name}: {e}")
            if 'doc_id' in locals():
                update_document_status(db, doc_id, "failed", 0)

    if stats["chunks_inserted"] > 0:
        os.makedirs(os.path.dirname(INDEX_PATH), exist_ok=True)
        faiss.write_index(index, INDEX_PATH)
        log_success(f"ğŸ’¾ ÄÃ£ lÆ°u FAISS index vÃ o {INDEX_PATH}")

    db.close_connections()

    log_info("\nğŸ“Š **BÃO CÃO Tá»”NG Káº¾T**")
    log_success(f"  âœ” Documents xá»­ lÃ½: {stats['docs']}")
    log_success(f"  âœ” Chunks thÃªm má»›i: {stats['chunks_inserted']}")
    log_warn(f"  âš ï¸ Chunks bá» qua: {stats['chunks_skipped']}")

if __name__ == "__main__":
    main()