venv) PS D:\\projects\\chatbotapp\\M1v3> python.exe .\\check\_[chunks.py](http://chunks.py)
=== Database Stats ===
total_chunks: 84
active_chunks: 84
inactive_chunks: 0
total_documents: 0
searches_last_24h: 0
database_size_mb: 0.46

=== Chunks in DB (max 50 rows) ===
ID=1, chunk_id=bienbanbangiao-000, doc_id=bienbanbangiao, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=2, chunk_id=bienbanbangiao-001, doc_id=bienbanbangiao, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=3, chunk_id=bienbanbangiao-002, doc_id=bienbanbangiao, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=4, chunk_id=bienbanbangiao-003, doc_id=bienbanbangiao, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=5, chunk_id=lythaito-000, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=6, chunk_id=lythaito-001, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=7, chunk_id=lythaito-002, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=8, chunk_id=lythaito-003, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=9, chunk_id=lythaito-004, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=10, chunk_id=lythaito-005, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=11, chunk_id=lythaito-006, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=12, chunk_id=lythaito-007, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=13, chunk_id=lythaito-008, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=14, chunk_id=lythaito-009, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=15, chunk_id=lythaito-010, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=16, chunk_id=lythaito-011, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=17, chunk_id=lythaito-012, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=18, chunk_id=lythaito-013, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=19, chunk_id=lythaito-014, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=20, chunk_id=lythaito-015, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=21, chunk_id=lythaito-016, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=22, chunk_id=lythaito-017, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=23, chunk_id=lythaito-018, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=24, chunk_id=lythaito-019, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=25, chunk_id=lythaito-020, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=26, chunk_id=lythaito-021, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=27, chunk_id=lythaito-022, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=28, chunk_id=lythaito-023, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=29, chunk_id=lythaito-024, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=30, chunk_id=lythaito-025, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=31, chunk_id=lythaito-026, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=32, chunk_id=lythaito-027, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=33, chunk_id=lythaito-028, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=34, chunk_id=lythaito-029, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=35, chunk_id=lythaito-030, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=36, chunk_id=lythaito-031, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=37, chunk_id=lythaito-032, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=38, chunk_id=lythaito-033, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=39, chunk_id=lythaito-034, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=40, chunk_id=lythaito-035, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=41, chunk_id=lythaito-036, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=42, chunk_id=lythaito-037, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=43, chunk_id=lythaito-038, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=44, chunk_id=lythaito-039, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=45, chunk_id=lythaito-040, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=46, chunk_id=lythaito-041, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=47, chunk_id=lythaito-042, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=48, chunk_id=lythaito-043, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=49, chunk_id=lythaito-044, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096
ID=50, chunk_id=lythaito-045, doc_id=lythaito, title=None, active=1, invalidated_by=None, embedding_len=4096

=== Embedding samples ===
Traceback (most recent call last):
File "D:\\projects\\chatbotapp\\M1v3\\check\_[chunks.py](http://chunks.py)", line 43, in <module>
main()
\~\~\~\~^^
File "D:\\projects\\chatbotapp\\M1v3\\check\_[chunks.py](http://chunks.py)", line 37, in main
emb = json.loads(row['embedding'])
File "C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\json\_*init*\_.py", line 341, in loads
s = s.decode(detect_encoding(s), 'surrogatepass')
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xed in position 0: invalid continuation byte
(venv) PS D:\\projects\\chatbotapp\\M1v3>

Vậy là nguyên nhân rõ rồi — cột `embedding` trong SQLite **không phải JSON hợp lệ**, mà là dữ liệu nhị phân (binary) đã bị lưu trực tiếp, nên khi `json.loads()` sẽ báo lỗi `UnicodeDecodeError`.

Điều này giải thích vì sao API báo `invalid_embeddings: 84` và việc tìm kiếm không ra kết quả:

- HybridRetriever sau khi lấy FAISS IDs sẽ gọi `search_chunks_advanced` → cột `embedding` không ảnh hưởng đến filter, nhưng bản thân dữ liệu embeddings có thể đã không match với FAISS index hoặc index chứa vector đúng nhưng text bị filter do document metadata không đồng bộ.

---

### Cách xử lý

Có 2 hướng:

#### 1. **Test FAISS trực tiếp** (bỏ qua SQLite hoàn toàn)

Tôi có thể viết một script `search_faiss_only.py` đọc `index.faiss`, lấy embedding từ model và tìm kiếm ngay trong FAISS, trả về ID, không động vào DB.  
 Như vậy sẽ biết index đang lưu vector gì và có match với query không.

#### 2. **Sửa lưu trữ embedding trong DB**

- Nếu muốn giữ embedding dạng JSON (để rebuild index), bạn cần chạy lại **quy trình import JSON → encode bằng model → lưu vector dạng list → json.dumps() vào DB**.
- Sau đó rebuild FAISS index từ embeddings trong DB để đồng bộ.

---

### Đề xuất bước kế tiếp để test nhanh

Tôi viết cho bạn một script test FAISS-only, không phụ thuộc DB:

```python
# search_faiss_only.py
import faiss
import numpy as np
from rag_system.api_service.models.embeddings import get_embedding_model

FAISS_INDEX_PATH = "rag_system/data/indexes/index.faiss"

def main():
    # Load FAISS
    index = faiss.read_index(FAISS_INDEX_PATH)
    print(f"FAISS index loaded with {index.ntotal} vectors.")

    # Load embedding model
    model = get_embedding_model()

    # Nhập câu hỏi
    query = input("Nhập câu hỏi: ").strip()
    q_emb = model.encode([query])[0].astype(np.float32)
    q_emb = q_emb / np.linalg.norm(q_emb)  # normalize

    # Search
    distances, ids = index.search(q_emb.reshape(1, -1), 5)
    print("\n=== FAISS raw results ===")
    for i, (idx, score) in enumerate(zip(ids[0], distances[0]), 1):
        print(f"{i}. FAISS ID: {idx}, Score: {score}")

if __name__ == "__main__":
    main()
```

Chạy:

```bash
python search_faiss_only.py
```

Nếu script này vẫn ra ID và score > 0 thì FAISS index hoạt động, nghĩa là vấn đề nằm ở SQLite filter.  
 Nếu trả toàn `-1` thì index không chứa vector match → cần import lại dữ liệu.

---

Bạn có muốn tôi làm **bước 1 (FAISS-only test)** trước để xác định nguyên nhân chính xác không?  
 Vì nếu FAISS đã trả kết quả, ta chỉ cần chỉnh filter DB hoặc mapping ID là xong.

(venv) PS D:\\projects\\chatbotapp\\M1v3> python.exe .\\search_faiss\_[only.py](http://only.py)
FAISS index loaded with 84 vectors.
Nhập câu hỏi: lý thái tổ là ai?

=== FAISS raw results ===

1. FAISS ID: 7148307199222121966, Score: 0.5282819271087646
2. FAISS ID: 2067500738662261011, Score: 0.47836461663246155
3. FAISS ID: 2324380954736222662, Score: 0.47614699602127075
4. FAISS ID: 420887159088736429, Score: 0.47572124004364014
5. FAISS ID: 4169995246002018979, Score: 0.45455408096313477 (venv) PS D:\\projects\\chatbotapp\\M1v3>

Kết quả này chứng minh là **FAISS index đang hoạt động tốt**, vì nó trả về 5 vector có điểm similarity khá cao với truy vấn `"lý thái tổ là ai?"`.

Như vậy nguyên nhân việc `HybridRetriever.retrieve()` trả về 0 kết quả **không phải** do FAISS, mà do giai đoạn lọc từ SQLite:

- Các ID trong FAISS (`7148307…`, `2067500…`…) **không trùng với cột** `id` **trong bảng** `chunks`.
- Lý do là FAISS index của bạn được build bằng `IndexFlatIP` hoặc `IndexIDMap2` nhưng IDs lại được gán từ **hash hoặc giá trị khác**, chứ không phải `rowid` của SQLite.
- Vì vậy, khi `search_chunks_advanced()` query `WHERE id IN (...)` thì không khớp ID nào → kết quả rỗng.

---

### Cách khắc phục

Có 2 lựa chọn:

#### **1. Đồng bộ lại FAISS ID với SQLite** `id`

Khi import dữ liệu:

```python
faiss_id = cursor.lastrowid
index.add_with_ids(embedding.reshape(1, -1), np.array([faiss_id]))
```

Như vậy FAISS ID sẽ chính là ID của row trong SQLite → HybridRetriever sẽ tìm được.

#### **2. Giữ FAISS ID hiện tại nhưng mapping sang chunk_id**

- Lưu FAISS ID hiện tại vào một cột riêng trong SQLite (vd `faiss_id`).
- Khi retrieve, thay vì query `id IN (...)`, bạn query `faiss_id IN (...)`.

---

### Đề xuất tạm thời để test nhanh

Bạn có thể chỉnh tạm `HybridRetriever.retrieve()`:

```python
# Thay vì lọc qua search_chunks_advanced, ta debug:
print("FAISS IDs:", valid_faiss_ids)
```

Rồi tự query DB:

```python
SELECT * FROM chunks WHERE chunk_id LIKE '%lythaito%' LIMIT 5;
```

Nếu thấy dữ liệu thì chắc chắn chỉ là vấn đề mapping ID.

---

Bạn có muốn tôi viết cho bạn **phiên bản HybridRetriever tạm thời bỏ qua DB** và chỉ trả về kết quả FAISS + chunk_id từ mapping thủ công, để bạn test ngay lập tức không?  
 Cách này giúp xác nhận tìm kiếm hoạt động trước khi chỉnh lại logic đồng bộ ID.

Tôi sẽ phân tích dựa trên toàn bộ tình huống vừa rồi — từ log API, dữ liệu SQLite, FAISS index và thiết kế `HybridRetriever` của bạn — để chỉ ra những điểm **cần xử lý lại** để hệ thống hoạt động đúng như ý tưởng ban đầu (một RAG hệ thống với FAISS + SQLite + lọc metadata).

---

## 1. Vấn đề cốt lõi

### 1.1. FAISS ID và SQLite ID không đồng bộ

- FAISS index đang lưu **ID kiểu số rất lớn** (vd: `7148307199222121966`), không trùng với `id` trong bảng `chunks` (vd: `5, 6, 7,...`).
- `HybridRetriever.retrieve()` lấy `valid_faiss_ids` → gọi `search_chunks_advanced()` với `chunk_ids=valid_faiss_ids`.
- Nhưng trong `search_chunks_advanced()` điều kiện SQL là:

  ```sql
  WHERE id IN (...)
  ```

  → Kết quả luôn rỗng vì ID không trùng.

**Giải pháp**:

- Khi import dữ liệu vào FAISS, cần gán FAISS ID = SQLite `id` (rowid).
- Nếu muốn giữ FAISS ID khác, cần lưu mapping (`faiss_id` ↔ `chunk_id`) trong SQLite và sửa truy vấn để tìm theo `faiss_id`.

---

### 1.2. Embedding trong SQLite không hợp lệ

- Cột `embedding` hiện đang chứa **nhị phân (binary)**, không phải JSON list float → `invalid_embeddings`.
- Điều này khiến:
  - Không thể rebuild FAISS index từ DB khi cần.
  - Health check luôn báo warning.
- Nguyên nhân: khi insert chunk, embedding chưa được `json.dumps()` trước khi lưu.

**Giải pháp**:

- Khi insert chunk:

  ```python
  embedding_json = json.dumps(embedding.tolist())
  ```
- Hoặc lưu dạng BLOB có schema rõ ràng và xử lý rebuild riêng.
- Chạy lại quá trình import JSON → encode → lưu đúng định dạng.

---

### 1.3. Thiếu bảng `documents` dữ liệu

- `total_documents` = 0 → tất cả `document_id` trong `chunks` hiện **không liên kết** với bảng `documents`.
- Điều này khiến `cleanup_orphaned_data()` luôn báo `orphaned_chunks` nếu có bật strict check.

**Giải pháp**:

- Khi import tài liệu, insert metadata vào bảng `documents`.
- `document_id` trong `chunks` phải tồn tại ở bảng `documents`.

---

### 1.4. Mapping FAISS ↔ Metadata

- Ý tưởng ban đầu của bạn: FAISS để tìm vector, SQLite để lọc metadata (`is_active`, `access_roles`, `categories`…).
- Hiện tại mapping ID sai → filter không chạy.
- Ngoài ra, `HybridRetriever.retrieve()` đang phụ thuộc **nặng** vào việc ID khớp → cần tách bước mapping ra để linh hoạt.

**Giải pháp**:

- Có một bảng `faiss_mapping`:

  ```sql
  faiss_id INTEGER PRIMARY KEY,
  chunk_id TEXT NOT NULL
  ```
- Khi retrieve:
  1. FAISS search → lấy `faiss_id`
  2. Mapping sang `chunk_id`
  3. Lấy metadata từ `chunks` bằng `chunk_id`.

---

### 1.5. Kiểm soát dữ liệu khi import

Hiện tại chưa có bước xác thực:

- Tránh duplicate `chunk_id`
- Tránh null text
- Đảm bảo embedding dimension đúng
- Ghi log khi import thất bại

**Giải pháp**:

- Viết một `import_manager` để xử lý batch import:
  - Validate JSON
  - Compute embeddings
  - Insert vào DB
  - Add vào FAISS (đúng ID)
  - Commit đồng bộ

---

## 2. Checklist các bước xử lý lại

| Hạng mục             | Tình trạng hiện tại         | Cần làm lại                                     |
|----------------------|-----------------------------|-------------------------------------------------|
| **FAISS ID ↔ SQLite ID** | Không khớp → lọc rỗng       | Gán FAISS ID = SQLite ID hoặc thêm bảng mapping |
| **Lưu embedding**        | Dạng binary, không JSON     | Lưu dạng JSON list hoặc BLOB chuẩn              |
| **Bảng** `documents`       | Trống                       | Import metadata document song song với chunks   |
| **Rebuild FAISS**        | Không thể vì embedding lỗi  | Sau khi sửa format embedding, cho phép rebuild  |
| **Import pipeline**      | Chưa validate dữ liệu       | Thêm validate: text, dimension, trùng ID        |
| **Health check**         | Luôn báo invalid_embeddings | Sửa format embedding, rebuild để hết warning    |

---

## 3. Quy trình đề xuất để sửa toàn bộ

1. **Backup DB & index**

   ```bash
   sqlite3 rag_system/data/metadata.db ".backup backup_metadata.db"
   cp rag_system/data/indexes/index.faiss index_backup.faiss
   ```
2. **Xóa FAISS index cũ** (nếu mapping sai không sửa được)

   ```bash
   rm rag_system/data/indexes/index.faiss
   ```
3. **Fix import script**
   - Khi insert chunk:

     ```python
     faiss_id = cursor.lastrowid
     index.add_with_ids(embedding.reshape(1, -1), np.array([faiss_id]))
     embedding_json = json.dumps(embedding.tolist())
     ```
   - Thêm insert vào bảng `documents`.
4. **Re-import dữ liệu JSON** theo pipeline chuẩn.
5. **Rebuild index định kỳ**:
   - Lọc `is_active = 1`
   - Lấy embedding từ DB (JSON)
   - Tạo FAISS mới
   - Ghi đè `index.faiss`
6. **Test trực tiếp HybridRetriever** để đảm bảo query ra kết quả.

---

Tóm lại:

- **Nguyên nhân chính**: Mapping ID giữa FAISS và DB sai + embedding trong DB không đúng định dạng.
- **Hướng khắc phục**: Đồng bộ lại ID khi import, lưu embedding đúng định dạng JSON, nhập metadata tài liệu vào bảng `documents`.
- Sau khi làm các bước này, hệ thống sẽ hoạt động đúng như ý tưởng ban đầu: FAISS tìm vector nhanh, SQLite lọc theo metadata.

---

Nếu bạn muốn, tôi có thể viết ngay cho bạn **script re-import JSON → DB + FAISS với mapping ID chuẩn** để bạn chạy 1 lần là đồng bộ cả hai bên.  
 Bạn có muốn tôi làm luôn không?